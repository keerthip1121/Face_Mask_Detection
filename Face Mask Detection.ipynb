{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We had a trained model that classifies images of 'with mask' and 'without mask'. We now use haarcascade frontal face xml file to detect faces from video captured by our webcam and apply model to detect whether the captured face is 'with mask' or 'without mask'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dowmload Haarcascade file of frontal face to detect face area\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cnn model \n",
    "model = load_model('mask_detect.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for webcam\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    bool_,img=cap.read()# captures frame and returns boolean value and captured image\n",
    "    if not bool_:\n",
    "        continue\n",
    "    # convert captured video to gray scale\n",
    "    gray_img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # use cascade to mark face in video\n",
    "    faces_detected = face_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "\n",
    "    # apply model to marked faces to predict wearing of mask or not by preprocessing the image  \n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "        roi_gray=cv2.resize(roi_gray,(100,100))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "        predictions = model.predict(img_pixels)\n",
    "\n",
    "        #find max indexed array\n",
    "        max_index = np.argmax(predictions[0])\n",
    "\n",
    "        emotions = ('WithMask','WithoutMask')\n",
    "        predicted_emotion = emotions[max_index]\n",
    "        color = [0,255,0] if predicted_emotion == 'WithMask' else [0,0,255]\n",
    "        \n",
    "        # marking rectangle around face printing text 'With mask' or 'Without mask'\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color,thickness=5)\n",
    "        cv2.putText(img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    resized_img = cv2.resize(img, (700, 500))\n",
    "    cv2.imshow('Mask or no mask detection',resized_img)\n",
    "\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):# wait until 'q' key is pressed \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In this way we can detect whether faces from video captured are wearing masks or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
